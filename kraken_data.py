import ccxt
import os
from dotenv import load_dotenv
import pandas as pd
import pytz
from datetime import datetime
import time
import ta.volatility
import json
import tempfile
import shutil
import threading
import logging
from logging.handlers import TimedRotatingFileHandler
import gzip
from dataclasses import dataclass, asdict, field
from typing import List, Optional, Any, Dict

try:
  import dateutil.parser as dateutil_parser
except Exception:
  dateutil_parser = None

try:
    from jsonschema import validate as jsonschema_validate, ValidationError
except Exception:
    jsonschema_validate = None
    ValidationError = Exception


# REGISTRO GLOBAL DE POSICIONES ABIERTAS (Manejo de estado)
OPEN_POSITIONS: List[Dict[str, Any]] = []
CLOSED_TRADES: List[Dict[str, Any]] = [] # <-- A√ëADIDO: Para guardar los resultados de PnL


@dataclass
class Position:
    symbol: str
    direction: str
    entry_price: float
    amount_base: float
    stop_loss: Optional[float]
    take_profit: Optional[float]
    status: str
    open_time: Any = field(default_factory=lambda: datetime.now(pytz.utc))

    def to_dict(self) -> Dict[str, Any]:
        d = asdict(self)
        # Asegurar que open_time es serializable (ISO)
        if isinstance(d.get('open_time'), datetime):
            d['open_time'] = d['open_time'].isoformat()
        return d

    @staticmethod
    def from_dict(d: Dict[str, Any]) -> 'Position':
        ot = d.get('open_time')
        if isinstance(ot, str):
            if dateutil_parser:
                ot_parsed = dateutil_parser.parse(ot)
            else:
                ot_parsed = datetime.fromisoformat(ot)
            d['open_time'] = ot_parsed
        return Position(**d)


# 1. Cargar variables del archivo .env
load_dotenv()

# Configuraci√≥n de logging con rotaci√≥n diaria + compresi√≥n
LOG_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'kraken.log')
def _rotator(source, dest):
    try:
        with open(source, 'rb') as sf, gzip.open(dest + '.gz', 'wb') as df:
            shutil.copyfileobj(sf, df)
        os.remove(source)
    except Exception:
        # Si la compresi√≥n falla, intentar mover el fichero sin comprimir
        try:
            shutil.move(source, dest)
        except Exception:
            pass

def _namer(name):
    return name + '.gz'

file_handler = TimedRotatingFileHandler(LOG_FILE, when='midnight', interval=1, backupCount=30, utc=True, encoding='utf-8')
file_handler.rotator = _rotator
file_handler.namer = _namer

stream_handler = logging.StreamHandler()

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s %(levelname)s %(message)s',
    handlers=[file_handler, stream_handler]
)

# 2. Inicializar la conexi√≥n
def initialize_kraken_exchange():
    """Inicializa la instancia de Kraken usando las credenciales del entorno."""
    try:
        exchange = ccxt.kraken({
            'apiKey': os.getenv('KRAKEN_API_KEY'),
            'secret': os.getenv('KRAKEN_SECRET'),
            'enableRateLimit': True,
        })
        logging.info("Conexi√≥n a Kraken inicializada correctamente.")
        return exchange
    except Exception as e:
        logging.error(f"Error al inicializar Kraken: {e}")
        return None


# Nombre del archivo para guardar las posiciones abiertas
POSITIONS_FILE = 'open_positions.json'
# Debounce/periodic save settings
_SAVE_LOCK = threading.Lock()
_LAST_SAVE_TIME = 0.0
_SAVE_DEBOUNCE_SECONDS = 1.0
_SAVE_PENDING = False

# JSON schema simple para validaci√≥n
POSITIONS_SCHEMA = {
    "type": "array",
    "items": {
        "type": "object",
        "required": ["symbol", "direction", "entry_price", "amount_base", "status", "open_time"]
    }
}

def load_open_positions():
    """Carga las posiciones abiertas desde un archivo JSON al inicio."""
    global OPEN_POSITIONS
    try:
        if os.path.exists(POSITIONS_FILE):
            with open(POSITIONS_FILE, 'r') as f:
                data = json.load(f)

                # Validar esquema si jsonschema est√° disponible
                if jsonschema_validate:
                    try:
                        jsonschema_validate(instance=data, schema=POSITIONS_SCHEMA)
                    except ValidationError as ve:
                        logging.warning(f"Esquema inv√°lido en {POSITIONS_FILE}: {ve}")

                # Convertir cada dict a Position para normalizar tipos
                loaded = []
                for item in data:
                    try:
                        pos = Position.from_dict(item)
                        loaded.append(pos.to_dict())
                    except Exception:
                        # Si falla conversi√≥n, mantener el dict original
                        loaded.append(item)

                OPEN_POSITIONS = loaded
                logging.info(f"{len(OPEN_POSITIONS)} posiciones abiertas cargadas desde {os.path.abspath(POSITIONS_FILE)}.")
                return
    except Exception as e:
        logging.warning(f"Error al cargar posiciones: {e}. Iniciando con lista vac√≠a.")
    
    OPEN_POSITIONS = []

def save_open_positions():
    """Guarda las posiciones abiertas en un archivo JSON."""
    global OPEN_POSITIONS
    # Escritura at√≥mica con debounce
    def _write_atomic(data_to_write):
        dirpath = os.path.dirname(os.path.abspath(POSITIONS_FILE)) or '.'
        fd, tmp_path = tempfile.mkstemp(prefix='._op_', dir=dirpath)
        try:
            with os.fdopen(fd, 'w') as tmpf:
                json.dump(data_to_write, tmpf, indent=4, default=str)
                tmpf.flush()
                os.fsync(tmpf.fileno())
            # Mover at√≥micamente
            shutil.move(tmp_path, POSITIONS_FILE)
            logging.info(f"Estado de posiciones guardado en {os.path.abspath(POSITIONS_FILE)}.")
        finally:
            # Asegurar que el tmpfile no quede si hubo error
            if os.path.exists(tmp_path):
                try:
                    os.remove(tmp_path)
                except Exception:
                    pass

    with _SAVE_LOCK:
        now = time.time()
        data_snapshot = []
        # Convertir Position-like dicts to serializables
        for p in OPEN_POSITIONS:
            if isinstance(p, Position):
                data_snapshot.append(p.to_dict())
            else:
                # intentar normalizar open_time
                p_copy = dict(p)
                ot = p_copy.get('open_time')
                if isinstance(ot, datetime):
                    p_copy['open_time'] = ot.isoformat()
                data_snapshot.append(p_copy)

        # Debounce: si √∫ltimo guardado fue hace menos de debounce, postergar
        global _LAST_SAVE_TIME, _SAVE_PENDING
        if now - _LAST_SAVE_TIME < _SAVE_DEBOUNCE_SECONDS:
            # marcar pendiente y lanzar un timer si no existe
            _SAVE_PENDING = True
            def _delayed():
                global _SAVE_PENDING, _LAST_SAVE_TIME
                _write_atomic(data_snapshot)
                _LAST_SAVE_TIME = time.time()
                _SAVE_PENDING = False

            t = threading.Timer(_SAVE_DEBOUNCE_SECONDS, _delayed)
            t.daemon = True
            t.start()
            return

        try:
            _write_atomic(data_snapshot)
            _LAST_SAVE_TIME = now
        except Exception as e:
            logging.error(f"Error al guardar posiciones: {e}")

        
# NUEVA FUNCI√ìN (o adaptaci√≥n)
def fetch_recent_data(exchange, symbol='BTC/USD', timeframe='1h', limit=50):
    """
    Descarga el n√∫mero limitado (N) de velas hist√≥ricas m√°s recientes.
    Recomendado para an√°lisis en tiempo real.
    """
    try:
        # ccxt por defecto usa el par√°metro 'limit' para obtener las velas m√°s recientes.
        ohlcv = exchange.fetch_ohlcv(
            symbol, 
            timeframe, 
            limit=limit 
        )
        
        if not ohlcv:
            logging.warning(f"No se obtuvieron datos recientes para {symbol}.")
            return None
            
        # 4. Compilaci√≥n de Datos en un √∫nico DataFrame
        headers = ['timestamp', 'open', 'high', 'low', 'close', 'volume']
        df = pd.DataFrame(ohlcv, columns=headers)
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        
        return df
        
    except Exception as e:
        logging.error(f"Error al obtener datos recientes para {symbol}: {e}")
        return None
    

def execute_live_trade(kraken, symbol, atr_multiplier=0.05, timeframe='1h', hours_to_analyze=50):
    """
    Ejecuta la estrategia de Sesgo de Tiempo en un activo espec√≠fico. 
    Obtiene los datos recientes (last N hours) para calcular el ATR y el Sesgo.
    """
    
    logging.info(f"--- [ LIVE TRADE: {symbol} ] Analizando...")
    
    # 1. Obtener Datos Recientes (Usando la nueva funci√≥n de l√≠mite)
    historical_data = fetch_recent_data(kraken, symbol, timeframe, limit=hours_to_analyze)

    if historical_data is None or historical_data.empty:
        logging.warning(f"No hay datos recientes para {symbol}. Saltando.")
        return

    # 2. An√°lisis del Sesgo de Tiempo
    processed_data = preprocess_data_for_time_bias(historical_data)
    data_with_zones = mark_kill_zones(processed_data)
    
    # Calcula el puntaje de sesgo (Gross Return Score)
    time_bias_score = analyze_gross_return(data_with_zones)

    # 3. Decisi√≥n y Ejecuci√≥n
    # Llama a la funci√≥n de simulaci√≥n que contiene toda la l√≥gica optimizada
    execute_trade_simulation(
        symbol, 
        time_bias_score, 
        atr_multiplier, 
        historical_data
    )
    
    # NOTA: Opcionalmente, puedes eliminar las llamadas a analyze_time_bias y analyze_all_hours
    # de este punto para que la ejecuci√≥n en vivo sea m√°s limpia y r√°pida, 
    # ya que solo son √∫tiles para el reporte y an√°lisis en backtesting.
    
    logging.info(f"{symbol} | Sesgo: {time_bias_score:.2f} | Decisi√≥n Registrada.")    
      

def preprocess_data_for_time_bias(df):
    """
    Normaliza el timestamp a UTC y calcula la volatilidad de la vela.
    """
    
    # 1. Asegurar UTC (si el timestamp no tiene una zona horaria asignada)
    # Convertimos el timestamp a un √≠ndice de pandas para facilitar el manejo.
    df = df.set_index(df['timestamp'])
    
    # Localizar (o asignar) la zona horaria UTC. 
    # Usamos .tz_localize para ASIGNAR la zona horaria a datos 'naive' (sin zona horaria).
    if df.index.tz is None:
        df.index = df.index.tz_localize(pytz.utc)

    # 2. Crear Columna de Hora (Para la estrategia de Kill Zones)
    df['hour_utc'] = df.index.hour
    
    # 3. Calcular Rango (Volatilidad)
    df['candle_range'] = df['high'] - df['low']
    
    logging.info(f"Datos pre-procesados. Zona horaria: {df.index.tz}")
    return df.reset_index(drop=True)


# Tiempos de ejemplo para la superposici√≥n Londres/Nueva York:
# La Kill Zone es de 08:00 a 12:00 UTC (4 horas de alta volatilidad)
KILL_ZONE_START = 14
KILL_ZONE_END = 18

def mark_kill_zones(df):
    """
    Marca las velas que caen dentro de la Kill Zone de alta liquidez.
    """
    # 1. Crear una columna booleana que es True si la hora est√° dentro del rango
    df['is_kill_zone'] = (df['hour_utc'] >= KILL_ZONE_START) & (df['hour_utc'] < KILL_ZONE_END)
    
    logging.info("Kill Zones marcadas en el DataFrame.")
    return df


# NUEVO INDICADOR: Devolver el Retorno Bruto (GR) de la Kill Zone
def analyze_gross_return(df):
    """Calcula el Retorno Bruto Promedio (GR) por vela en la Kill Zone."""
    
    # Calcular el cambio absoluto por vela
    df['gross_return'] = df['close'] - df['open']
    
    # -----------------------------------------------------------------
    # CORRECCI√ìN CR√çTICA: Filtrar por el valor booleano TRUE/FALSE
    # -----------------------------------------------------------------
    # 1. Calcular el retorno promedio en la Kill Zone (donde 'is_kill_zone' es True)
    kill_zone_gr = df[df['is_kill_zone'] == True]['gross_return'].mean()
    
    # 2. Calcular el retorno promedio fuera de la Kill Zone (donde 'is_kill_zone' es False)
    low_liquidity_gr = df[df['is_kill_zone'] == False]['gross_return'].mean()
    
    # Mostrar resultados en consola
    logging.info("An√°lisis de Retorno Bruto Promedio (por Vela):")
    logging.info("-" * 50)
    
    # Manejo de NaN para evitar errores
    if pd.isna(kill_zone_gr):
        logging.warning("KILL ZONE (14:00 a 18:00 UTC): NaN (Movimiento promedio)")
        sesgo = "Neutro (Error de C√°lculo o Datos insuficientes)."
        return 0.0 # Devolver 0.0 en caso de error para que el if/elif del main no falle
        
    # Continuaci√≥n si no es NaN
    logging.info(f"KILL ZONE (14:00 a 18:00 UTC): ${kill_zone_gr:.2f} (Movimiento promedio)")
    logging.info(f"LOW LIQUIDITY (Otras Horas): ${low_liquidity_gr:.2f} (Movimiento promedio)")
    logging.info("-" * 50)
    
    if kill_zone_gr > 0:
        sesgo = "Ligeramente Alcista (el precio tiende a subir)."
    elif kill_zone_gr < 0:
        sesgo = "Ligeramente Bajista (el precio tiende a bajar)."
    else:
        sesgo = "Neutro."
        
    logging.info(f"Sesgo de Direcci√≥n en la KILL ZONE: {sesgo}")
    
    # DEVUELVE el indicador clave: Retorno Bruto de la Kill Zone
    return kill_zone_gr



def calculate_atr(df, window=20): 
    """
    Calcula el Average True Range (ATR) para la volatilidad, utilizando una ventana
    de N velas (por defecto 20) para el c√°lculo del valor final.
    """
    # Usamos la ventana definida (ahora 20) para el c√°lculo del ATR.
    # Esto asegura que el valor ATR de la √∫ltima vela refleje la volatilidad de las 20 velas anteriores.
    
    # Aseg√∫rate de que las columnas 'high', 'low', 'close' est√©n presentes
    df['atr'] = ta.volatility.average_true_range(df['high'], df['low'], df['close'], window=window)
    
    # Devolver el ATR de la √∫ltima vela (este valor ya es el resultado del c√°lculo de 20 periodos)
    return df['atr'].iloc[-1]

def calculate_exit_levels(entry_price, atr_value, direction):
    """Calcula los niveles de Stop Loss y Take Profit."""
    
    # Par√°metros de Riesgo/Recompensa
    SL_MULTIPLIER = 1.5  # Asumir 1.5x el ATR de riesgo
    TP_MULTIPLIER = 3.0  # Asumir 3.0x el ATR de recompensa (R:R 1:2)
    
    risk_amount = atr_value * SL_MULTIPLIER
    profit_amount = atr_value * TP_MULTIPLIER

    if direction == "LONG (COMPRA)":
        # SL: Por debajo del precio de entrada
        stop_loss = entry_price - risk_amount
        # TP: Por encima del precio de entrada
        take_profit = entry_price + profit_amount
    
    elif direction == "SHORT (VENTA)":
        # SL: Por encima del precio de entrada
        stop_loss = entry_price + risk_amount
        # TP: Por debajo del precio de entrada
        take_profit = entry_price - profit_amount
    
    else:
        # En caso neutral, no hay niveles
        return None, None
    
    return round(stop_loss, 2), round(take_profit, 2)


def monitor_and_close_positions(current_price_data, exchange):
    """
    Monitorea posiciones abiertas contra SL/TP/Time Exit.
    current_price_data: Diccionario con precios actuales (simulados o reales).
    exchange: Instancia de CCXT para obtener la hora y potencialmente ejecutar √≥rdenes reales.
    """
    global OPEN_POSITIONS, CLOSED_TRADES 

    # 1. Obtener la hora actual UTC
    # Usamos la hora local de la m√°quina y la convertimos a UTC
    now_utc = datetime.now(pytz.utc)
    current_utc_hour = now_utc.hour
    
    # Si estamos dentro de la Kill Zone, no deber√≠amos aplicar Time Exit todav√≠a.
    # El Time Exit solo aplica DESPU√âS de la hora de cierre de la Kill Zone.
    time_exit_allowed = (current_utc_hour >= KILL_ZONE_END)
    
    if time_exit_allowed:
        logging.info(f"--- [ CIERRE POR TIEMPO ACTIVO ] --- Hora actual: {now_utc.strftime('%H:%M:%S')} UTC")
    else:
        logging.info(f"--- [ MONITOREO SL/TP ] --- Hora actual: {now_utc.strftime('%H:%M:%S')} UTC")


    # Recorrer las posiciones de atr√°s hacia adelante para eliminar sin problemas
    for i in range(len(OPEN_POSITIONS) - 1, -1, -1):
        pos = OPEN_POSITIONS[i]
        # Aceptar tanto `Position` como `dict` en la lista de posiciones.
        # Si es `Position`, convertir y reemplazar el elemento en la lista
        # para mantener consistencia con el resto del c√≥digo que usa dicts.
        if isinstance(pos, Position):
            pos = OPEN_POSITIONS[i] = pos.to_dict()
        symbol = pos['symbol']
        
        current_price = current_price_data.get(symbol)
        
        if current_price is None:
            logging.warning(f"ADVERTENCIA: Precio actual no encontrado para {symbol}. Saltando monitoreo.")
            continue
            
        exit_reason = None
        close_price = None 

        # 2. L√≥gica de CIERRE por SL/TP (Prioridad M√°xima)
        if pos['direction'] == 'LONG (COMPRA)':
            if current_price >= pos['take_profit']:
                exit_reason = "TAKE PROFIT (TP)"
                close_price = pos['take_profit'] # Usar nivel fijo
            elif current_price <= pos['stop_loss']:
                exit_reason = "STOP LOSS (SL)"
                close_price = pos['stop_loss'] # Usar nivel fijo
        
        elif pos['direction'] == 'SHORT (VENTA)':
            if current_price <= pos['take_profit']: 
                exit_reason = "TAKE PROFIT (TP)"
                close_price = pos['take_profit'] # Usar nivel fijo
            elif current_price >= pos['stop_loss']: 
                exit_reason = "STOP LOSS (SL)"
                close_price = pos['stop_loss'] # Usar nivel fijo

        # 3. L√≥gica de CIERRE por Tiempo (Time Exit)
        # Solo se ejecuta si no se ha cerrado por SL/TP y el tiempo ha expirado
        if exit_reason is None and time_exit_allowed:
            exit_reason = "TIME EXIT (KZ EXPIR√ì)"
            close_price = current_price # Cerrar al precio de mercado (simulado)
            
        # 4. Ejecuci√≥n del Cierre y Registro
        if exit_reason:
            
            # Calcular PnL (Ganancia/P√©rdida)
            pnl_usd = (close_price - pos['entry_price']) * pos['amount_base']
            
            # Si fue un SHORT, el c√°lculo debe ser inverso 
            if pos['direction'] == 'SHORT (VENTA)':
                pnl_usd = -pnl_usd 

            pnl_status = "GANANCIA" if pnl_usd > 0 else "P√âRDIDA"
            
            logging.info(f"CIERRE {symbol} | Motivo: {exit_reason} | PnL: ${pnl_usd:.2f} ({pnl_status})")
            
            # Mover la posici√≥n a la lista de cerradas y eliminar de la lista abierta
            pos['status'] = 'CLOSED'
            pos['exit_price'] = close_price 
            pos['exit_reason'] = exit_reason
            pos['pnl_usd'] = pnl_usd 
            
            CLOSED_TRADES.append(OPEN_POSITIONS.pop(i))

            save_open_positions()
            
    if not OPEN_POSITIONS:
        logging.info("NO HAY POSICIONES ABIERTAS PENDIENTES")
    else:
        logging.info(f"{len(OPEN_POSITIONS)} POSICIONES ABIERTAS PENDIENTES")


# ----------------------------------------------------
# NUEVA FUNCI√ìN: SIMULACI√ìN DE ENTRADA DE TRADING
# ----------------------------------------------------

def execute_trade_simulation(symbol, bias_score, atr_multiplier_value, historical_data): 
    """
    Simula una orden de mercado con c√°lculo de Stop Loss y Take Profit.
    Ahora incluye filtro de robustez ATR M√≠n/M√°x.
    """
    global OPEN_POSITIONS

    # 1. Obtener precios y calcular ATR
    try:
        entry_price = historical_data['close'].iloc[-1] 
        # Se llama a la funci√≥n ATR, que ahora debe tener la l√≥gica de las √∫ltimas 20 velas
        atr_value = calculate_atr(historical_data.copy())
        open_time = historical_data.index[-1]
        
        # C√ÅLCULO DEL UMBRAL DIN√ÅMICO
        dynamic_threshold = atr_value * atr_multiplier_value 

    except Exception as e:
        logging.error(f"ERROR al calcular ATR/Precios para {symbol}: {e}")
        return
    
    # ----------------------------------------------------
    # NUEVO FILTRO DE ROBUSTEZ: ATR M√≠nimo y M√°ximo
    # ----------------------------------------------------
    # Se establecen l√≠mites de sentido com√∫n para evitar trades en volatilidad nula o extrema.
    MIN_ATR_USD = 0.05  
    MAX_ATR_USD = 100.0 

    if atr_value < MIN_ATR_USD:
        logging.info(f"DECISI√ìN: MANTENERSE AL MARGEN (VOLATILIDAD MUERTA). ATR (${atr_value:.2f}) < Umbral M√≠nimo (${MIN_ATR_USD:.2f}).")
        return

    if atr_value > MAX_ATR_USD:
        logging.info(f"DECISI√ìN: MANTENERSE AL MARGEN (VOLATILIDAD EXTREMA). ATR (${atr_value:.2f}) > Umbral M√°ximo (${MAX_ATR_USD:.2f}).")
        return
    # ----------------------------------------------------

    # 2. L√≥gica de Decisi√≥n (Identificaci√≥n de Direcci√≥n) - √öNICA VEZ
    if bias_score > dynamic_threshold:
        direction = "LONG (COMPRA)"
    elif bias_score < -dynamic_threshold:
        direction = "SHORT (VENTA)"
    else:
        direction = "NEUTRAL"
        logging.info(f"DECISI√ìN: MANTENERSE AL MARGEN (SESGO NEUTRO). Umbral requerido: ${dynamic_threshold:.2f}")
        return
        
    # 3. Calcular los niveles de salida 
    stop_loss, take_profit = calculate_exit_levels(entry_price, atr_value, direction)

    # 4. Simulaci√≥n y Reporte de la Orden
    amount_usd = 100.0  # Invertir 100 USD
    amount_base = amount_usd / entry_price
    
    logging.info(f"DECISI√ìN: INICIAR {direction}")
    logging.info("-" * 50)
    logging.info("--- ORDEN SIMULADA ---")
    logging.info(f"Activo: {symbol}")
    logging.info(f"Direcci√≥n: {direction}")
    logging.info(f"Score (GR): ${bias_score:.2f}")
    logging.info(f"Precio Entrada: ${entry_price:.2f}")
    logging.info(f"Cantidad Base: {amount_base:.5f} {symbol.split('/')[0]}")
    logging.info(f"Volatilidad (ATR): ${atr_value:.2f}")
    logging.info(f"STOP LOSS (SL): ${stop_loss:.2f}")
    logging.info(f"TAKE PROFIT (TP): ${take_profit:.2f}")
    logging.info("-" * 50)

    # 5. Guardar la posici√≥n
    # Crear instancia Position para mayor consistencia
    ot = open_time
    # Convertir pandas.Timestamp a datetime si es necesario
    try:
        import pandas as _pd
        if isinstance(ot, _pd.Timestamp):
            ot = ot.to_pydatetime()
    except Exception:
        pass

    pos_obj = Position(
        symbol=symbol,
        direction=direction,
        entry_price=entry_price,
        amount_base=amount_base,
        stop_loss=stop_loss,
        take_profit=take_profit,
        status='OPEN',
        open_time=ot
    )
    OPEN_POSITIONS.append(pos_obj)

    save_open_positions()


def print_final_trade_report():
    """Imprime un reporte anal√≠tico de nivel profesional para el grupo."""
    global CLOSED_TRADES
    if not CLOSED_TRADES:
        logging.info("--- REPORTE: Sin operaciones cerradas en este ciclo ---")
        return
        
    df_results = pd.DataFrame(CLOSED_TRADES)
    
    # C√°lculos M√©tricos
    total_pnl = df_results['pnl_usd'].sum()
    wins = df_results[df_results['pnl_usd'] > 0]['pnl_usd']
    losses = df_results[df_results['pnl_usd'] <= 0]['pnl_usd']
    
    gross_profit = wins.sum()
    gross_loss = abs(losses.sum())
    profit_factor = gross_profit / gross_loss if gross_loss != 0 else float('inf')
    win_rate = (len(wins) / len(df_results)) * 100

    # Formateo del Reporte para el Grupo
    logging.info("=" * 60)
    logging.info("üìä AUDITOR√çA DE DISCIPLINA AUTOMATIZADA")
    logging.info("=" * 60)
    logging.info(df_results[['symbol', 'direction', 'exit_reason', 'pnl_usd']].to_string(index=False))
    logging.info("-" * 60)
    logging.info(f"‚úÖ Trades Ganados: {len(wins)} | ‚ùå Trades Perdidos: {len(losses)}")
    logging.info(f"üéØ Win Rate: {win_rate:.2f}%")
    logging.info(f"üìà Profit Factor: {profit_factor:.2f}")
    logging.info(f"üí∞ PNL TOTAL DE LA JORNADA: ${total_pnl:.2f}")
    logging.info("=" * 60)
    logging.info("Nota: Ejecuci√≥n 100% algor√≠tmica sin intervenci√≥n humana.")

def main():
    # ---------------------------------------------
    # 1. PARAMETRIZACI√ìN GLOBAL (¬°FIJADA!)
    # ---------------------------------------------
    TARGET_ASSETS = [
        'BTC/USD', 'ADA/USD', 'XRP/USD', 'SOL/USD', 
        'ETH/USD', 'LTC/USD', 'DOT/USD', 'BCH/USD', 'UNI/USD', 'LINK/USD'
    ]
    OPTIMAL_ATR_MULTIPLIER = 0.05 
    TIME_FRAME = '1h'
    HOURS_TO_ANALYZE = 50 

    # Limpieza necesaria
    global CLOSED_TRADES, OPEN_POSITIONS
    CLOSED_TRADES = []
    
    kraken = initialize_kraken_exchange()
    if not kraken:
        logging.error("Fallo la inicializaci√≥n de Kraken. Deteniendo el proceso.")
        return

    # NUEVO: Verificaci√≥n de Autenticaci√≥n (Moviendo la l√≥gica del if __name__ == '__main__':)
        try:
            balance = kraken.fetch_balance()
            logging.info("Autenticaci√≥n exitosa. Saldo cargado.")
        except Exception as e:
            logging.error(f"Error CR√çTICO de autenticaci√≥n: {e}. El bot no puede operar. Deteniendo.")
            return

    # =========================================================
    # --- SIMULACI√ìN DE EJECUCI√ìN LIVE ---
    # =========================================================

    load_open_positions()

    # [MODULO 1: APERTURA DE POSICIONES]
    # Este m√≥dulo se ejecutar√≠a solo una vez al d√≠a (ej: 14:00 UTC)
    logging.info(f"[MODULO 1] INICIANDO APERTURA (Multiplicador ATR: {OPTIMAL_ATR_MULTIPLIER:.2f})")
    
    for symbol in TARGET_ASSETS:
        execute_live_trade(
            kraken, 
            symbol=symbol, 
            atr_multiplier=OPTIMAL_ATR_MULTIPLIER,
            hours_to_analyze=HOURS_TO_ANALYZE
        )

    # [MODULO 2: MONITOREO Y CIERRE REAL]
    logging.info("[MODULO 2] OBTENIENDO PRECIOS DE CIERRE REALES DE KRAKEN...")
    
    real_current_prices = {}
    for symbol in TARGET_ASSETS:
        try:
            ticker = kraken.fetch_ticker(symbol)
            real_current_prices[symbol] = ticker['last'] # Captura el √∫ltimo precio real
            logging.info(f"Precio capturado: {symbol} -> ${real_current_prices[symbol]}")
        except Exception as e:
            logging.error(f"Error al capturar precio real de {symbol}: {e}")

    # Ahora monitoreamos y cerramos con datos REALES del mercado
    monitor_and_close_positions(real_current_prices, kraken) 

    # [MODULO 3: REPORTE FINAL]
    print_final_trade_report()


if __name__ == "__main__":
	main()